{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR5g6cOZzoFd",
        "colab_type": "code",
        "outputId": "a4809805-e214-4482-d710-9c95edbb2331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4ounRflzqMv",
        "colab_type": "code",
        "outputId": "0ffc57b8-d27a-46a2-8757-90ec8fb58221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7tVxPfdzt8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "import sys\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjI8ZGWjzvuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 0\n",
        "numpy.random.seed(seed)\n",
        "tf.set_random_seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4tR4y-6zwrM",
        "colab_type": "code",
        "outputId": "adcc01cb-7948-4c46-e289-43c4b47e51bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 11s 1us/step\n",
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7fN2qVZzx7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1bXJ3JjzzVy",
        "colab_type": "code",
        "outputId": "eb03c436-8e4e-4139-972c-e32de22c50b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        }
      },
      "source": [
        "figure,axes = plt.subplots(nrows=3, ncols=5)\n",
        "figure.set_size_inches(18,12)\n",
        "\n",
        "plt.gray()\n",
        "print(\"label={}\".format(y_train[0:15]))\n",
        "\n",
        "col = 0\n",
        "for row in range(0,3):\n",
        "    col = row * 5\n",
        "    axes[row][0].matshow(X_train[col])\n",
        "    axes[row][1].matshow(X_train[col+1])\n",
        "    axes[row][2].matshow(X_train[col+2])\n",
        "    axes[row][3].matshow(X_train[col+3])\n",
        "    axes[row][4].matshow(X_train[col+4])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label=[5 0 4 1 9 2 1 3 1 4 3 5 3 6 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x864 with 15 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrT6NVrTz0kA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0],784)   # 60000, 28, 28 -> 60000, 784로 변경\n",
        "# 데이터 값의 범위 0~255 -> 0~1 \n",
        "X_train.astype('float64')  \n",
        "X_train = X_train/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYqNJuXaz2T4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YM_P0mZz3s_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 테스트 데이터 전처리\n",
        "X_test = X_test.reshape(X_test.shape[0],784)\n",
        "X_test.astype('float64')\n",
        "X_test = X_test/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_4VV76tz4_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OneHotEncoding - 10진수의 값을 0, 1의 값을 갖는 벡터로 표현\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2S-V7twz6Wt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cV9j-aI50hcF",
        "colab_type": "text"
      },
      "source": [
        "**모델 생성**\n",
        "* input_dim = 784\n",
        "* 첫번째 은닉층 512개의 노드, 활성화함수는 relu\n",
        "* 두번째 은닉층 120개의 노드, 활성화함수는 relu\n",
        "* 세번재 은닉층 10개의 노드, 활성화함수는 softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f4iSeGJz76h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "d56662da-ceb3-4995-dcf5-0096ceaa33d6"
      },
      "source": [
        "m = Sequential()\n",
        "m.add(Dense(512, input_dim=784, activation='relu'))\n",
        "m.add(Dense(120, activation='relu'))\n",
        "m.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Jz-Cyzy2Asg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F2QZbaI2JHI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eb1544f1-b50b-43d7-9def-6cb039b45c2a"
      },
      "source": [
        "history = m.fit(X_train, Y_train, validation_data=(X_test, Y_test),\n",
        "                epochs=30,\n",
        "                batch_size=200,\n",
        "                verbose=1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.2738 - accuracy: 0.9220 - val_loss: 0.1316 - val_accuracy: 0.9617\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0983 - accuracy: 0.9705 - val_loss: 0.0912 - val_accuracy: 0.9713\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0641 - accuracy: 0.9805 - val_loss: 0.0795 - val_accuracy: 0.9756\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0451 - accuracy: 0.9860 - val_loss: 0.0902 - val_accuracy: 0.9718\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0314 - accuracy: 0.9907 - val_loss: 0.0736 - val_accuracy: 0.9781\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 0.0243 - accuracy: 0.9929 - val_loss: 0.0743 - val_accuracy: 0.9783\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.0672 - val_accuracy: 0.9802\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 0.0676 - val_accuracy: 0.9797\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.0797 - val_accuracy: 0.9772\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0811 - val_accuracy: 0.9797\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.0722 - val_accuracy: 0.9809\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.0983 - val_accuracy: 0.9746\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.0973 - val_accuracy: 0.9769\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.0896 - val_accuracy: 0.9799\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.0813 - val_accuracy: 0.9822\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0931 - val_accuracy: 0.9782\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.1043 - val_accuracy: 0.9772\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0940 - val_accuracy: 0.9797\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.0966 - val_accuracy: 0.9800\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.1073 - val_accuracy: 0.9798\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.0840 - val_accuracy: 0.9827\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0775 - val_accuracy: 0.9846\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 5.3619e-04 - accuracy: 0.9999 - val_loss: 0.0824 - val_accuracy: 0.9839\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.1116 - val_accuracy: 0.9770\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.0914 - val_accuracy: 0.9812\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0907 - val_accuracy: 0.9814\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.1032 - val_accuracy: 0.9806\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0952 - val_accuracy: 0.9818\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0991 - val_accuracy: 0.9810\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0936 - val_accuracy: 0.9846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTXAvpi730YR",
        "colab_type": "text"
      },
      "source": [
        "**예측**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm7EdSlo2Sy3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "fc6b89ce-6a59-465b-f44e-c6ee82fb4f8b"
      },
      "source": [
        "pred = m.predict(X_test)\n",
        "pred.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tff5ivap3Jx5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "4f26239f-8d1c-44e7-b317-163719f4f59c"
      },
      "source": [
        "pred[0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.10977218, 0.08261932, 0.10562111, 0.08080696, 0.09061593,\n",
              "       0.09047072, 0.12147234, 0.1097765 , 0.11366057, 0.09518434],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAnc1L9H3Osn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0d3765eb-8982-4bfb-b2c8-f3a450d2885b"
      },
      "source": [
        "np.argmax(pred[0])   # argmax : 가장 큰 값의 위치를 알려줌\n",
        "# 6번째 값이 제일 크므로 6을 예측"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVL7X5mW36ta",
        "colab_type": "text"
      },
      "source": [
        "모델의 평가결과\n",
        "* 첫번째는 cost\n",
        "* 두번째는 정확도"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doP5xSQ-3X5Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "c77183c4-01da-4e19-d634-8646d1f09d6a"
      },
      "source": [
        "m.evaluate(X_test, Y_test)[1]   # 정확도"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 78us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10270000249147415"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0aWZaei4JlQ",
        "colab_type": "text"
      },
      "source": [
        "epoch, batch_size, 은닉층의 수를 조정해가면서 결과 확인해보기\n",
        "* epoch 수 늘리기\n",
        "* 배치사이즈는 적게하는 것이 정확도가 올라감\n",
        "* 은닉층은\n",
        "* 은닉층의 노드수를 조정해가면서 결과확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otewpfJ5DWNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f8083518-cc43-45e5-de71-7fff00c16ba6"
      },
      "source": [
        "%%time\n",
        "\n",
        "m = Sequential()\n",
        "m.add(Dense(512, input_dim=784, activation='relu'))\n",
        "m.add(Dense(120, activation='relu'))\n",
        "m.add(Dense(10, activation='softmax'))\n",
        "\n",
        "m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = m.fit(X_train, Y_train, validation_data=(X_test, Y_test),\n",
        "                epochs=50,\n",
        "                batch_size=200,\n",
        "                verbose=1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.2737 - accuracy: 0.9213 - val_loss: 0.1325 - val_accuracy: 0.9626\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0962 - accuracy: 0.9708 - val_loss: 0.0828 - val_accuracy: 0.9732\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0625 - accuracy: 0.9809 - val_loss: 0.0748 - val_accuracy: 0.9775\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0427 - accuracy: 0.9867 - val_loss: 0.0683 - val_accuracy: 0.9788\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0303 - accuracy: 0.9905 - val_loss: 0.0640 - val_accuracy: 0.9793\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0221 - accuracy: 0.9937 - val_loss: 0.0626 - val_accuracy: 0.9817\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0169 - accuracy: 0.9950 - val_loss: 0.0660 - val_accuracy: 0.9807\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.0671 - val_accuracy: 0.9811\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0712 - val_accuracy: 0.9812\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 0.0754 - val_accuracy: 0.9805\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.0697 - val_accuracy: 0.9811\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.0762 - val_accuracy: 0.9806\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.0778 - val_accuracy: 0.9809\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.0796 - val_accuracy: 0.9807\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0872 - val_accuracy: 0.9812\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.0841 - val_accuracy: 0.9800\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0760 - val_accuracy: 0.9825\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0815 - val_accuracy: 0.9818\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0839 - val_accuracy: 0.9821\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0932 - val_accuracy: 0.9818\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0844 - val_accuracy: 0.9818\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0854 - val_accuracy: 0.9831\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0989 - val_accuracy: 0.9817\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0950 - val_accuracy: 0.9801\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.0895 - val_accuracy: 0.9809\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0877 - val_accuracy: 0.9826\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0912 - val_accuracy: 0.9837\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0982 - val_accuracy: 0.9822\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.0971 - val_accuracy: 0.9807\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.1103 - val_accuracy: 0.9808\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.0999 - val_accuracy: 0.9826\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0924 - val_accuracy: 0.9834\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 4.6936e-04 - accuracy: 0.9999 - val_loss: 0.0931 - val_accuracy: 0.9846\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 1.9242e-04 - accuracy: 0.9999 - val_loss: 0.0891 - val_accuracy: 0.9848\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 4.1452e-05 - accuracy: 1.0000 - val_loss: 0.0891 - val_accuracy: 0.9851\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 2.3003e-05 - accuracy: 1.0000 - val_loss: 0.0896 - val_accuracy: 0.9852\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 1.8263e-05 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9854\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 1.5245e-05 - accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 0.9855\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 1.2923e-05 - accuracy: 1.0000 - val_loss: 0.0910 - val_accuracy: 0.9855\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 1.1084e-05 - accuracy: 1.0000 - val_loss: 0.0916 - val_accuracy: 0.9858\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 9.5849e-06 - accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 0.9857\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 8.2595e-06 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9857\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 7.2238e-06 - accuracy: 1.0000 - val_loss: 0.0934 - val_accuracy: 0.9858\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 6.2558e-06 - accuracy: 1.0000 - val_loss: 0.0939 - val_accuracy: 0.9858\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 5.4530e-06 - accuracy: 1.0000 - val_loss: 0.0944 - val_accuracy: 0.9857\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 4.7302e-06 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 0.9859\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 4.1338e-06 - accuracy: 1.0000 - val_loss: 0.0957 - val_accuracy: 0.9859\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 3.6151e-06 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9860\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 3.1499e-06 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9861\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 2.7338e-06 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9862\n",
            "CPU times: user 1min 28s, sys: 10.8 s, total: 1min 39s\n",
            "Wall time: 1min 16s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQRaTwlI5ivH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "61dc1d0b-03a6-4204-d33a-727c8d5e0c84"
      },
      "source": [
        "m.evaluate(X_test, Y_test)[1]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 65us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9861999750137329"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZqP7xfC7tld",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "24c3d0be-5a1d-49b8-a15d-c016b7016560"
      },
      "source": [
        "%%time\n",
        "\n",
        "m = Sequential()\n",
        "m.add(Dense(512, input_dim=784, activation='relu'))\n",
        "m.add(Dense(120, activation='relu'))\n",
        "m.add(Dense(10, activation='softmax'))\n",
        "\n",
        "m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = m.fit(X_train, Y_train, validation_data=(X_test, Y_test),\n",
        "                epochs=100,\n",
        "                batch_size=200,\n",
        "                verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.2644 - accuracy: 0.9251 - val_loss: 0.1228 - val_accuracy: 0.9624\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0956 - accuracy: 0.9714 - val_loss: 0.0823 - val_accuracy: 0.9742\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0614 - accuracy: 0.9818 - val_loss: 0.0773 - val_accuracy: 0.9757\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0430 - accuracy: 0.9868 - val_loss: 0.0678 - val_accuracy: 0.9792\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0305 - accuracy: 0.9908 - val_loss: 0.0697 - val_accuracy: 0.9794\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0220 - accuracy: 0.9933 - val_loss: 0.0662 - val_accuracy: 0.9801\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.0730 - val_accuracy: 0.9795\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.0773 - val_accuracy: 0.9790\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.0796 - val_accuracy: 0.9778\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.0717 - val_accuracy: 0.9803\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.0797 - val_accuracy: 0.9790\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 0.0787 - val_accuracy: 0.9800\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.0754 - val_accuracy: 0.9812\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0771 - val_accuracy: 0.9824\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.0868 - val_accuracy: 0.9807\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.0895 - val_accuracy: 0.9801\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.0868 - val_accuracy: 0.9806\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0825 - val_accuracy: 0.9825\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0885 - val_accuracy: 0.9819\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.1018 - val_accuracy: 0.9801\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.1052 - val_accuracy: 0.9803\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.0998 - val_accuracy: 0.9802\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0777 - val_accuracy: 0.9837\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 6.2744e-04 - accuracy: 0.9999 - val_loss: 0.0831 - val_accuracy: 0.9845\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 1.0028e-04 - accuracy: 1.0000 - val_loss: 0.0822 - val_accuracy: 0.9850\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 5.1316e-05 - accuracy: 1.0000 - val_loss: 0.0829 - val_accuracy: 0.9849\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 3.9359e-05 - accuracy: 1.0000 - val_loss: 0.0834 - val_accuracy: 0.9849\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 3.2127e-05 - accuracy: 1.0000 - val_loss: 0.0838 - val_accuracy: 0.9850\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 2.6825e-05 - accuracy: 1.0000 - val_loss: 0.0846 - val_accuracy: 0.9848\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 2.2898e-05 - accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 0.9849\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 1.9610e-05 - accuracy: 1.0000 - val_loss: 0.0857 - val_accuracy: 0.9848\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 1.6881e-05 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9850\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 1.4488e-05 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9849\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 1.2728e-05 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9850\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 1.1013e-05 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9849\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 9.5838e-06 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9849\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 8.3512e-06 - accuracy: 1.0000 - val_loss: 0.0895 - val_accuracy: 0.9850\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 7.3029e-06 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9850\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 6.3258e-06 - accuracy: 1.0000 - val_loss: 0.0910 - val_accuracy: 0.9850\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 5.5751e-06 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 0.9850\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 4.8928e-06 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9851\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 4.2433e-06 - accuracy: 1.0000 - val_loss: 0.0932 - val_accuracy: 0.9850\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 3.7431e-06 - accuracy: 1.0000 - val_loss: 0.0939 - val_accuracy: 0.9850\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 3.2782e-06 - accuracy: 1.0000 - val_loss: 0.0943 - val_accuracy: 0.9852\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 2.8622e-06 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9849\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 2.5278e-06 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 0.9852\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 2.1880e-06 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 0.9851\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 1.9090e-06 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 0.9851\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 1.6657e-06 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9847\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 1.4482e-06 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9847\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 1.2655e-06 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9849\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 1.1008e-06 - accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 0.9852\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 9.5392e-07 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9850\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 8.4332e-07 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9847\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 7.2770e-07 - accuracy: 1.0000 - val_loss: 0.1025 - val_accuracy: 0.9850\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 6.3422e-07 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9849\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 5.5100e-07 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9850\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 4.7466e-07 - accuracy: 1.0000 - val_loss: 0.1052 - val_accuracy: 0.9854\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 4.0767e-07 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9853\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 3.7733e-07 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 0.9851\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 3.1779e-07 - accuracy: 1.0000 - val_loss: 0.1078 - val_accuracy: 0.9852\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 2.6853e-07 - accuracy: 1.0000 - val_loss: 0.1087 - val_accuracy: 0.9850\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 2.3608e-07 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9852\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 2.0290e-07 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9853\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 1.7670e-07 - accuracy: 1.0000 - val_loss: 0.1104 - val_accuracy: 0.9854\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 1.5397e-07 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9851\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 1.3583e-07 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9853\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 1.1622e-07 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9853\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 1.0109e-07 - accuracy: 1.0000 - val_loss: 0.1140 - val_accuracy: 0.9852\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 8.8376e-08 - accuracy: 1.0000 - val_loss: 0.1143 - val_accuracy: 0.9851\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 7.7327e-08 - accuracy: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9850\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 6.7166e-08 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9851\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 5.9613e-08 - accuracy: 1.0000 - val_loss: 0.1171 - val_accuracy: 0.9852\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 5.1520e-08 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9850\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 4.5802e-08 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9853\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 3.9417e-08 - accuracy: 1.0000 - val_loss: 0.1195 - val_accuracy: 0.9851\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 3.4952e-08 - accuracy: 1.0000 - val_loss: 0.1201 - val_accuracy: 0.9852\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 3.0808e-08 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9852\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 2.6973e-08 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9851\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 2.3973e-08 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9852\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 2.1513e-08 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9853\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 1.9165e-08 - accuracy: 1.0000 - val_loss: 0.1233 - val_accuracy: 0.9852\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 1.6961e-08 - accuracy: 1.0000 - val_loss: 0.1240 - val_accuracy: 0.9851\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 1.5108e-08 - accuracy: 1.0000 - val_loss: 0.1247 - val_accuracy: 0.9851\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 1.3669e-08 - accuracy: 1.0000 - val_loss: 0.1251 - val_accuracy: 0.9851\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 1.2290e-08 - accuracy: 1.0000 - val_loss: 0.1261 - val_accuracy: 0.9851\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 1.1053e-08 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9852\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 9.9997e-09 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 0.9851\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 9.1116e-09 - accuracy: 1.0000 - val_loss: 0.1277 - val_accuracy: 0.9850\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 8.2572e-09 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 0.9852\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 7.5022e-09 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.9854\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 6.7949e-09 - accuracy: 1.0000 - val_loss: 0.1294 - val_accuracy: 0.9851\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 6.2803e-09 - accuracy: 1.0000 - val_loss: 0.1297 - val_accuracy: 0.9853\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 5.7240e-09 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 0.9851\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 5.2949e-09 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 0.9853\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 4.8975e-09 - accuracy: 1.0000 - val_loss: 0.1312 - val_accuracy: 0.9851\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 4.4922e-09 - accuracy: 1.0000 - val_loss: 0.1315 - val_accuracy: 0.9853\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 4.2439e-09 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9852\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 3.8822e-09 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9851\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 3.6498e-09 - accuracy: 1.0000 - val_loss: 0.1327 - val_accuracy: 0.9850\n",
            "CPU times: user 2min 47s, sys: 17.8 s, total: 3min 5s\n",
            "Wall time: 2min 26s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYUQSCnX71YJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "125488db-10c6-4ad3-d3a4-197a233a9d6c"
      },
      "source": [
        "m.evaluate(X_test, Y_test)[1]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 65us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9850000143051147"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1FeRuue-hRu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "129469e9-70e6-48b1-8b54-5308853de56f"
      },
      "source": [
        "%%time\n",
        "\n",
        "m = Sequential()\n",
        "m.add(Dense(512, input_dim=784, activation='relu'))\n",
        "m.add(Dense(120, activation='relu'))\n",
        "m.add(Dense(10, activation='softmax'))\n",
        "\n",
        "m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = m.fit(X_train, Y_train, validation_data=(X_test, Y_test),\n",
        "                epochs=50,\n",
        "                batch_size=100,\n",
        "                verbose=1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 0.2218 - accuracy: 0.9354 - val_loss: 0.1055 - val_accuracy: 0.9677\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0831 - accuracy: 0.9748 - val_loss: 0.0792 - val_accuracy: 0.9741\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0525 - accuracy: 0.9837 - val_loss: 0.0666 - val_accuracy: 0.9796\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.0368 - accuracy: 0.9884 - val_loss: 0.0750 - val_accuracy: 0.9772\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0301 - accuracy: 0.9901 - val_loss: 0.0678 - val_accuracy: 0.9789\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0210 - accuracy: 0.9931 - val_loss: 0.0738 - val_accuracy: 0.9795\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.0761 - val_accuracy: 0.9802\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 0.0840 - val_accuracy: 0.9779\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.0125 - accuracy: 0.9955 - val_loss: 0.0898 - val_accuracy: 0.9792\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.0777 - val_accuracy: 0.9812\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.0794 - val_accuracy: 0.9834\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.1045 - val_accuracy: 0.9776\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.0985 - val_accuracy: 0.9795\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.0094 - accuracy: 0.9966 - val_loss: 0.0816 - val_accuracy: 0.9823\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.0933 - val_accuracy: 0.9820\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0835 - val_accuracy: 0.9824\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0098 - accuracy: 0.9964 - val_loss: 0.0927 - val_accuracy: 0.9813\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.0891 - val_accuracy: 0.9804\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.0964 - val_accuracy: 0.9809\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.0966 - val_accuracy: 0.9810\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.1002 - val_accuracy: 0.9796\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.1038 - val_accuracy: 0.9811\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.1100 - val_accuracy: 0.9810\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.1074 - val_accuracy: 0.9806\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1083 - val_accuracy: 0.9818\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0966 - val_accuracy: 0.9830\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.1219 - val_accuracy: 0.9793\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.1025 - val_accuracy: 0.9824\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.1162 - val_accuracy: 0.9808\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1294 - val_accuracy: 0.9796\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.1102 - val_accuracy: 0.9808\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0959 - val_accuracy: 0.9846\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.1036 - val_accuracy: 0.9841\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.1504 - val_accuracy: 0.9799\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.1064 - val_accuracy: 0.9829\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.1320 - val_accuracy: 0.9817\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.1415 - val_accuracy: 0.9793\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.1223 - val_accuracy: 0.9817\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.1178 - val_accuracy: 0.9814\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1187 - val_accuracy: 0.9801\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.1425 - val_accuracy: 0.9796\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.1081 - val_accuracy: 0.9842\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.1057 - val_accuracy: 0.9838\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.1114 - val_accuracy: 0.9842\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.1162 - val_accuracy: 0.9835\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.1331 - val_accuracy: 0.9832\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.1356 - val_accuracy: 0.9802\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1273 - val_accuracy: 0.9820\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.1322 - val_accuracy: 0.9832\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.1231 - val_accuracy: 0.9839\n",
            "CPU times: user 2min 42s, sys: 20.8 s, total: 3min 3s\n",
            "Wall time: 2min 19s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPpaMOll-0V5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "942eff02-ff0f-4f18-e9de-ec9547632bde"
      },
      "source": [
        "m.evaluate(X_test, Y_test)[1]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 65us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9839000105857849"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvkiDIeB-tPX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82692508-cf6b-4705-9f84-a562c805fc85"
      },
      "source": [
        "%%time\n",
        "\n",
        "m = Sequential()\n",
        "m.add(Dense(512, input_dim=784, activation='relu'))\n",
        "m.add(Dense(120, activation='relu'))\n",
        "m.add(Dense(10, activation='softmax'))\n",
        "\n",
        "m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = m.fit(X_train, Y_train, validation_data=(X_test, Y_test),\n",
        "                epochs=50,\n",
        "                batch_size=50,\n",
        "                verbose=1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.2019 - accuracy: 0.9395 - val_loss: 0.1003 - val_accuracy: 0.9705\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0780 - accuracy: 0.9760 - val_loss: 0.0801 - val_accuracy: 0.9752\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0544 - accuracy: 0.9831 - val_loss: 0.0641 - val_accuracy: 0.9815\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0378 - accuracy: 0.9879 - val_loss: 0.0771 - val_accuracy: 0.9755\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0304 - accuracy: 0.9900 - val_loss: 0.0889 - val_accuracy: 0.9751\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0248 - accuracy: 0.9917 - val_loss: 0.0782 - val_accuracy: 0.9797\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0194 - accuracy: 0.9936 - val_loss: 0.0819 - val_accuracy: 0.9798\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.0203 - accuracy: 0.9935 - val_loss: 0.0944 - val_accuracy: 0.9796\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.0921 - val_accuracy: 0.9751\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0145 - accuracy: 0.9953 - val_loss: 0.0770 - val_accuracy: 0.9813\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.1018 - val_accuracy: 0.9773\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0959 - val_accuracy: 0.9797\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 0.0863 - val_accuracy: 0.9827\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0963 - val_accuracy: 0.9815\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.0937 - val_accuracy: 0.9815\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.1038 - val_accuracy: 0.9814\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 0.1080 - val_accuracy: 0.9812\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.1036 - val_accuracy: 0.9833\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.0991 - val_accuracy: 0.9827\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.1182 - val_accuracy: 0.9791\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.1013 - val_accuracy: 0.9834\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.1086 - val_accuracy: 0.9825\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.1159 - val_accuracy: 0.9813\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.1095 - val_accuracy: 0.9823\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.1404 - val_accuracy: 0.9796\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.1174 - val_accuracy: 0.9824\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.1136 - val_accuracy: 0.9820\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.1383 - val_accuracy: 0.9830\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0080 - accuracy: 0.9980 - val_loss: 0.1252 - val_accuracy: 0.9832\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.1149 - val_accuracy: 0.9838\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.1101 - val_accuracy: 0.9843\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.1160 - val_accuracy: 0.9819\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.1396 - val_accuracy: 0.9820\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.1477 - val_accuracy: 0.9815\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.1345 - val_accuracy: 0.9829\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.1576 - val_accuracy: 0.9821\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.1390 - val_accuracy: 0.9812\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.1412 - val_accuracy: 0.9814\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.1321 - val_accuracy: 0.9829\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.1450 - val_accuracy: 0.9831\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 0.1644 - val_accuracy: 0.9817\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.1596 - val_accuracy: 0.9812\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.1665 - val_accuracy: 0.9806\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.1514 - val_accuracy: 0.9825\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.1354 - val_accuracy: 0.9839\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.1677 - val_accuracy: 0.9803\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.1590 - val_accuracy: 0.9820\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.1697 - val_accuracy: 0.9822\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.1962 - val_accuracy: 0.9795\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.1812 - val_accuracy: 0.9805\n",
            "CPU times: user 5min 2s, sys: 35.2 s, total: 5min 37s\n",
            "Wall time: 4min 19s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I36hRz0AgVK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "da135287-95e7-4aeb-b2e8-3690f094f6d4"
      },
      "source": [
        "m.evaluate(X_test, Y_test)[1]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 63us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9804999828338623"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiaSRCjyDLVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul29RyTu-kLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}